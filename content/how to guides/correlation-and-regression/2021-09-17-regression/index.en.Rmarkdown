---
title: Linear Regression Exercise-1 in Python
author: Carlos Rodriguez
date: '2021-09-17'
slug: regression
categories: []
tags: []
subtitle: ''
summary: ''
authors: []
lastmod: '2021-09-17T22:43:40-06:00'
featured: no
image:
  caption: ''
  focal_point: ''
  preview_only: no
projects: []
type: book
weight: 10
draft: true
---


The following describes a Python-based workflow for creating a linear regression model to examine e-commerce data from an online clothing store. The store is attempting to learn where to focus their efforts to increase their yearly sales. All data are fabricated and were sourced from the Python for Data Science and Machine Learning Bootcamp by Pieran Data hosted on Udemy.com.

```{r setup, include=FALSE}
knitr::opts_chunk$set(warning = FALSE)
library(kableExtra)
library(reticulate)

#conda_list()
use_condaenv("r-reticulate")
```

### Import Packages
```{python}
# Data Analysis & Visualization Packages
import numpy as np
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt

# Linear Regression Packages
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn import metrics
```

### Load Data
```{python}
customers = pd.read_csv('Ecommerce Customers')
```

### Inspect Data
Before analysing and visualizing the data, we will take a look at the structure of the data and make note of all of different variables. As of this writing, pandas tables do not readily display well within R markdown. To get around this snag, I took advantage of R's reticulate and kableExtra packages to display the first few rows of the data frame.
```{python, eval = FALSE}
customers.head(3)
customers.describe()
customers.info()
```

```{r}
#R code to display pandas table
df <- reticulate::py$customers
kable(head(df, n=3))
```

### Exploratory Data Analysis with Seaborn
After taking a look the tabulated data, we can make some basic visualizations to show the relationships between all of the numerical variables such as Time on Website, Time on App, Length of Membership, and Yearly Amount Spent. One place to start is to display paired plots with the Seaborn package.
```{python, plot4, fig.cap = 'Pairplot of all continous variables in the customers data frame.'}
sns.pairplot(data = customers)
plt.close()
```

After inspecting the paired plots, the relationship between Length of Membership and Yearly Amount Spent stands out. In the code chunk below, Seaborn was used to build a linear model plot of these two variables. In addition to displaying a scatterplot of the data, the lmplot displays a regression line that characterizes the relationship between the variables.
```{python, plot5, fig.cap = 'Linear model plot of the Length of Membership and Yearly Amount Spent.'}
sns.lmplot(x = "Length of Membership", y = "Yearly Amount Spent", data = customers)
plt.close()
```
### Prepare Data for Linear Regression Modelling
After performing some exploratory data analysis, we can then move on to building a linear model. First,  we will need to prepare the data by collecting all of the response variables and predictor variables into separate data frames. Next, the data are split into separate training and testing data sets with the `train_test_split()` function from the scikit-learn package.
```{python}
# Preparing numeric data for training and testing a regression model ie cross validation
# customers.columns # Prints the columns that are then copied and pasted int X an y.
X = customers[['Avg. Session Length', 'Time on App', 'Time on Website', 'Length of Membership']]
y = customers["Yearly Amount Spent"]

# Splitting the data into test and train datasets, holding out 30% for testing
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=101)

```

### Train Linear Regression Model
After creating our training set data, a linear model can be fit. In this case we will build a model that will predict the Yearly Amount Spent from the remaining  continuous variables in the e-commerce data set. Finally, we will create a data frame to print out the model coefficients.
```{python}
# Initialize an empty LinearyRegression() object
lm = LinearRegression()
```

```{python}
# Fit the x and y variables. In other words, predict y (yearly amount spent), 
# from all of the numerical X variables
lm.fit(X_train,y_train)
```
```{python}
# print the coefficients to each "feature" in the dataset, feature would be 
# interchangeable with variable
coeff_df = pd.DataFrame(lm.coef_,X.columns,columns=['Coefficient'])
```
```{r}
coeffs <- reticulate::py$coeff_df
kable(coeffs)
```

### Test Linear Regression Model
After building a model with the training data, our next step is to use the predictor variables in the testing data and our model, to make predictions about the Yearly Amount Spent. Then we can compare how well our predicted values match up with actual values in the testing data.

```{python, plot6, fig.cap = 'Scatterplot of the predicted and actual y values from the testing data set.'}
# Predict y from the X variables in the test set with the linear model created in the train set
predictions = lm.predict(X_test)
sns.scatterplot(x = y_test, y = predictions, data = pd.DataFrame(y_test, predictions))
plt.show()
plt.close()
```

```{python, include = FALSE}
# alternative form of plotting
# plot the actual Y (from test set), with the predicted y.
#plt.scatter(y_test, predictions)
#

#plot6 = sns.scatterplot(x = y_test, y = predictions, data = pd.DataFrame(y_test, predictions))
#(plot6)
```


### Evaluate Linear Regression Model
There are a number of ways that one can evaluate regression models. These metrics include the mean absolute error, the mean squared error, the root mean squared error, and R squared (explained variance score). The R squared valued can obtained by the `metrics.explained_variance_score()` function of the scikit-learn package. Without getting into the weeds, the R squared value is a measure of the proportion of variance in one variable that is explained by another. In this context, roughly 98% of the variance in Yearly Amount Spent can be explained by Length of Membership. As a reminder, these are fabricated data for illustrative purposes only and it would be rare to see such a relationship out in the wild.
```{python}
metrics.explained_variance_score(y_test, predictions)
```

```{python, include = FALSE}
#print('MAE:', metrics.mean_absolute_error(y_test, predictions))
#print('MSE:', metrics.mean_squared_error(y_test, predictions))
#print('RMSE:', np.sqrt(metrics.mean_squared_error(y_test, predictions)))
```

### Visually Inspect Residuals
Our last step is to plot the residuals which are the differences between the predicted Yearly Amount Spent values using the generted model and the actual values in the test data set. We would generally expect these to be normally distributed, otherwise linear regression may be a poor analysis choice for these data.
```{python}
sns.histplot((y_test-predictions),bins=50, kde = True)
plt.show()
plt.close()
```

### Interpretation
According to the regression coefficients, for each unit increase in the predictor variables Avg. Session Length, Time on App, Time on Website, and Length of Membership, we would expect a respectivley 25.98, 38.59, 0.19, and 61.28 unit increase in the Yearly Amount Spent response variable. Thus, the clothing company may be best served by focusing their efforts on the Length of Membership and perhaps the Time on App measures. Perhaps there means within the company to maintain or improve membership services and application development. However, it should be noted that although these variables are related, it is beyond the scope of this analysis to determine causal relationships. We don't exactly know if Yearly Amount Spent or Length of Membership drives the other or if there is an additional intermediary variable that is presently unknown. However, for now we have atleast determined a strong relationship between these two variables.


<!-- Older code and text in which joint plots wouldn't display properly-->

<!-- ```{python, plot1, fig.cap = 'Joint plot between Time on Website and Yearly Amount Spent.',} -->
<!-- sns.jointplot(x = 'Time on Website', y = 'Yearly Amount Spent', data = customers) -->
<!-- plt.close() -->


<!-- ``` -->

<!-- ```{r, include = FALSE,eval=FALSE} -->
<!-- sns <- import('seaborn') -->
<!-- plt <- import('matplotlib.pyplot') -->
<!-- pd <- import('pandas') -->
<!-- ``` -->

<!-- ```{r, include = FALSE, eval=FALSE} -->
<!-- sns$pairplot(r_to_py(df[,4:8])) -->
<!-- plt$show() -->
<!-- ``` -->


<!-- Next, we will take a look at a joint plot of Time on App and Yearly Amount Spen. There seems to be a stronger relationship here when compared to Time on Website and Yearly Amount Spent, but nothing that stands out. -->
<!-- ```{python, plot2, fig.cap = 'Joint plot between Time on App and Yearly Amount Spent.'} -->
<!-- sns.jointplot(x = "Time on App", y = "Yearly Amount Spent", data = customers) -->
<!-- plt.close() -->


<!-- ``` -->

<!-- In this plot, we examine Time on App and Length of Membership using the hex type of plot. Of all of the plots generated so far, these two variables seem to demonstrate the strongest relationship. -->
<!-- ```{python, plot3, fig.cap = 'Joint plot between Time on App and Length of Membership.'} -->
<!-- sns.jointplot(x = "Time on App", y = "Length of Membership", data = customers, kind = "hex") -->
<!-- plt.close() -->
<!-- ``` -->