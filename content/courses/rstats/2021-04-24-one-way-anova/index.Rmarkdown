---
title: One-way ANOVA
author: Carlos Rodriguez
date: '2021-04-24'
slug: one-way-anova
categories: []
tags: []
subtitle: ''
summary: ''
authors: []
lastmod: '2021-04-24T21:53:52-06:00'
featured: no
image:
  caption: ''
  focal_point: ''
  preview_only: no
projects: []
type: book
weight: 10
---


ANOVA is a commonly used statistical technique to compare differences among two or more means. In this module, we will cover how to perform a one-way ANOVA with the jmv and rstatix packages. A one-way ANOVA is appropriate for data in which groups differ along one categorical variable, but do not differ in the dependent variable


### The data set
For this demo we will use the data from Chapter 3, Exercise 9 in the AMCP package. In this exercise, a psychologist assigned 12 subjects to one of 4 different psychological treatments. These treatments consisted of rational-emotive, psychoanalytic, client-centered, and behavioral therapies. The 4 different treatments were used to investigate which therapy is more effective at reducing phobia scores.

For these data, Group represents the type of therapy the participant was randomly assigned to. Scores represent the score from a post-therapy fear scale where higher numbers indicate higher levels of phobia. Finally, each of the 12 rows represent each subject.
```{r warning=FALSE}
library(AMCP)

# Load the data
data(C3E9)

# Display part of the data
head(C3E9)
```

### Perform ANOVA Tests {#tests}
<!-- -----------------------TABS---------------------------------- -->
{{< tabs tabTotal="4" tabID="1" tabName1="jmv" tabName2="rstatix" tabName3="Welch's jmv" tabName4="Welch's rstatix"  >}}

<!-- -----------------------Tab 1---------------------------------- -->
{{< tab tabNum="1" >}}
Jmv is a package that comes from the standalone <a href="https://jamovi.org/"> jamovi </a> statistical spreadsheet software. Jamovi was designed as an alternative to costly statistical analysis software packages like SPSS or SAS and runs R underneath the hood. The developers of jamovi also released an R package with all of the functions of their standalone version.  

With the `anovaOneW()` function, we will predict Scores by Group (`Scores ~ Group`), set the data to be analyzed as C3E9, set `fishers = TRUE` and `welchs = FALSE`, otherwise the function will run the default Welch's ANOVA. We will also set the `phMethod = 'tukey'` to conduct posthoc tests, Lastly, we want to set `descPlot = TRUE` to plot means and confidence intervals.

```{r, plot1, fig.cap = 'anovaOneW plot of means and 95% confidence intervals by group.', warning=FALSE,  }
library(jmv)
library(AMCP)

# Load the data
data(C3E9)

# Conduct ANOVA test
anovaOneW(formula = Scores ~ Group, 
          data = C3E9, 
          fishers = TRUE, 
          welchs = FALSE, 
          descPlot = TRUE,
          phMethod = 'tukey'
          )
```


{{< /tab >}}
<!-- -----------------------Tab 2---------------------------------- -->
{{< tab tabNum="2" >}}
The rstatix package is another way of programming statistical tests in R. One of the benefits of the rstatix package is that it meshes well with the pipe (`%>%`) operator from the tidyverse package. This facilitates grouping data with the `group_by()` function and conducting pairwise comparisons, generating summary data, and other statistical computations like calculating effect sizes. We'll see an example of this in the code chunk below. The same developer of the rstatix package also developed the ggpubr package which simplifies producing ggplot2 figures. In this demo, the ggpubr package is loaded primarily to simplify producing a jamovi style plot.

The sample code of conducting the `anova_test()` is not too different than the `anovaOneW()` function in jmv. However, for this approach, we will need to change our Group variable to factor, otherwise `anova_test()` will think we will want to predict scores by a numeric variable rather than a categorical one. Next, we specify a formula predicting Scores by Group (`Scores ~ Group`). Then we tell the function that we want to analyze the C3E9 data, specify our dependent variable (dv; Scores), set the effect size output to partial eta squared ("pes"), and then set the sum of squares method to type III.

```{r rstatix, message=FALSE, warning=FALSE}
library(AMCP)
library(rstatix)
library(ggpubr)

# Load data
data(C3E9)

# Convert group to factor
C3E9$Group <- as.factor(C3E9$Group)

# Conduct ANOVA test
anova_test(Scores ~ Group, 
           data = C3E9, 
           dv = Scores, 
           effect.size = "pes", 
           type = 3
           )
```
### Posthoc Tests
To get the output for the post-hoc tests, we will run the `tukey_hsd()` function on the same data with the same formula (`Scores ~ Group`)
```{r tukey_hsd}
# Tukey posthoc tests
C3E9 %>%
  tukey_hsd(Scores ~ Group)
```

```{r bonferroni}
# Bonferroni corrected posthoc tests
C3E9 %>% 
  pairwise_t_test(Scores ~ Group, p.adjust.method = "bonferroni")
```

<!-- To produce a jmv style plot, things get a little trickier. First, we will need to calculate means and confidence intervals. Luckily, `get_summary_stats()` can do this painlessly because of the pipe operator from the tidyverse package. Essentially, the C3E9 data is fed to `group_by()` which will separate the data by Group, then the output is fed in `get_summary_stats()` which will compute descriptive statistics such as means, medians, confidence intervals, and others. The summary_data is then what we will use to generate a plot with the `ggplot()` function.   -->


```{r summary, include=FALSE}
# # Use get_summary_stats to compute the 95% CI
# summary_data <- C3E9 %>% 
#   group_by(Group) %>% 
#   get_summary_stats(Scores)
# 
# # Print part of the data
# head(summary_data)
```

<!-- The ggplot code is the trickiest part of using this approach. I'll attempt to explain the basic components here, but don't get discouraged if it doesn't make sense. It can take a while to fully get a hold of ggplot. I know it frustrated me plenty when I started with it. First, summary_data is used as the input, because it contains the means and confidence intervals. Next, we will specify what to plot on the x axis and what to plot on the y axis. Then, we will tell ggplot to add a layer of geometric element in the form of error bars. We can then set the ymin and ymax of the error bars as mean-ci and mean+ci as these values are in the input summary_data. Next, we will want to add some points (geom_point), then change their fill, color, and shape. The ggtitle will add a title to our plot, while ylab changes the label on the y axis. To wrap things up, we will add a theme to the plot to change the background, and then set the title to be centered horizontally. -->

```{r ggplot, fig.cap = 'ggplot of means and 95% confidence intervals by group.', include=FALSE}
# Generate a plot of mean and 95% CIs
# ggplot(summary_data, aes(x = Group, y = mean)) +
#   geom_errorbar(aes(ymin=mean-ci, ymax=mean+ci), 
#                 width = 0.1, 
#                 color = "blue") +
#   geom_point(fill = "white", 
#              shape = 21, 
#              size = 3, 
#              color = "blue") +
#   ggtitle("Mean (95% CI)") +
#   ylab("Scores") +
#   theme_pubr() +
#   theme(plot.title = element_text(hjust = 0.5))
```

### Plot the data  

One way to produce a plot of the data is to use the ggpubr package. The ggpubr package is a wrapper for ggplot2 and serves to simplify the ggplot2 syntax. The only drawback is that it may not have all of the flexibility of ggplot2. However, if you're new to R, ggpubr is a gentle introduction to making figure. In this next code chunk, I use the `ggpubr()` function on our C3E9 data, specify the x and y variables, set add to `"mean"` to plot the means, set `desc_stat = "mean_ci"` to plot the confidence intervals, set `error.plot = "errorbar"` to draw the error bars, and `width = .1` to specify the length of errorbar tips. The rest of the options are straightforward.
```{r ggpubr, fig.cap = 'Plot of means and 95% confidence intervals produced by ggpbur.', message=FALSE, warning=FALSE, include=TRUE}
ggerrorplot(C3E9,
       x = "Group",
       y = "Scores",
       add = "mean",
       desc_stat = "mean_ci",
       error.plot = "errorbar",
       width = .1,
       color = "blue",
       title = "Mean (95% CI)",
)

```
{{< /tab >}}

<!-- -----------------------Tab 3---------------------------------- -->
{{< tab tabNum="3" >}}
The three primary assumptions for ANOVA are as follows:  
 1. The data (more specifically the residuals) are normally distributed.  
 2. Homogeneity of variance.  
 3. The groups tested need to be independent.

There may be times when data fail to meet the some of these assumptions. In situations where  assumptions 1 and 3 are met, but assumption 2 is not, then Welch's ANOVA becomes an option to compare multiple means. The omnibus test of a Welch's ANOVA can be followed by Games-Howell post-hoc tests. One drawback, however, is that the Welch's ANOVA is restricted to only one explanatory factor unlike other ANOVA designs. 

### jmv
The following code chunk demonstrate how to code a Welch's ANOVA in R with the jmv and rstatix packages. The jmv approach uses the exact same function as the Fisher's one-way ANOVA and can take many of the same options to produce plots and conduct tests of normality and equality of variance (homogeneity of variance) with the `norm = TRUE` and `eqv = TRUE` options. Games-Howell post-hoc tests are produced by setting `phMethod = 'gamesHowell'`.
```{r welch jmv}
# Conduct Welch's ANOVA
anovaOneW(formula = Scores ~ Group,
          data = C3E9,
          welchs = TRUE,
          norm = TRUE,
          eqv = TRUE,
          phMethod = 'gamesHowell'
          )
```
{{< /tab >}}

<!-- -----------------------Tab 4---------------------------------- -->

{{< tab tabNum="4" >}}
To conduct a Welch's ANOVA with rstatix, the `welch_anova_test()` function is required. The syntax to conduct the actual test is rather simple. In the following code chunk, I've chosen to explicitly declare `formula = Scores ~ Group` and `data = C3E9`.  However, you could just as easily specify the dataframe and formula as long as data is the first entered variable. Similarly, data and formula do not need to be explicitly specified for the `games_howell_test()` function, but have chosen to do so in this example for consistency. To produce the Shapiro-Wilk's test of normality as in the jmv output, we need to first create an analysis of variance (aov) model with the base R `aov()` function. rstatix does contain its own `shapiro_test()` function, but it will not test normality of the residuals, only the actual values. We can then nest the output of that function in the `residuals()`, and then nest that output in the `shapiro.test()` function. Finally, for the homogeneity of variance test, we will use the rstatix `levene_test()` function specifying a formula and a dataframe. Base R also can also plot the Residuals vs Fitted values and generate Q-Q (quantile-quantile) plots from an `aov()` object to examine homogeneity of variance and normality respectively and commented code is also included in the following code chunk.
```{r welch rstatix}
# Conduct Welch's ANOVA
welch_anova_test(formula = Scores ~ Group,
                 data = C3E9)

# Alternative syntax
# welch_anova_test(C3E9, 
#                  Scores ~ Group)

# Games-Howell post-hoc tests
games_howell_test(formula = Scores ~ Group,
                  data = C3E9, 
                  conf.level = 0.95, 
                  detailed = FALSE)


# Produce Q-Q plots
# plot(aov(formula = Scores ~ Group, data = C3E9), 2)

# Base R Shapiro-Wilk test on residuals of the aov object
shapiro.test(residuals(aov(formula = Scores ~ Group, data = C3E9)))

# Residuals vs Fitted values plot
# plot(aov(formula = Scores ~ Group, data = C3E9), 1)

# rstatix Levene's test for homogeneity of variance
levene_test(formula = Scores ~ Group,
            data = C3E9)
```
{{< /tab >}}
{{< /tabs >}}

[Back to tabs](#tests)

### Interpret the output
For the omnibus test, we obtain a significant effect of Group [F(3,8) = 10, p < 0.01] which suggests that the means of the 4 groups are not equal. In other words, one of the treatments may be significantly different than another. The post-hoc tests that perform all possible combinations of pairwise comparisons also indicate a significant difference between group 1 and 2, between group 1 and 4, and between group 2 and 3.  

### Wrap Up
One of the benefits of the `anovaOneW()` function lies in eliminating the need to write code to produce a plot of means and confidence intervals. What is produced with one option within the `anovaOneW()` command, takes additional packages and several lines of code to produce with ggplot. It's main disadvantage is that `anovaOneW()` is limited in it post-hoc tests options.  You can select either 'tukey' or none for a traditional one-way ANOVA, but you could get additional correction methods with the `ANOVA()` in jmv. If you're starting out with R, the jmv package will surely give you a head start in terms of analyzing and visualizing simple one-way ANOVA tests.

### References
<div id="refs" class="references">

<div id="ref-R-ggpubr">

Kassambara, Alboukadel. 2020a. *Ggpubr: ’Ggplot2’ Based Publication Ready Plots*. <https://CRAN.R-project.org/package=ggpubr>.

</div>

<div id="ref-R-rstatix">

———. 2020b. *Rstatix: Pipe-Friendly Framework for Basic Statistical Tests*. <https://CRAN.R-project.org/package=rstatix>.

</div>

<div id="ref-R-AMCP">

Maxwell, Scott, Harold Delaney, and Ken Kelley. 2020. *AMCP: A Model Comparison Perspective*. <https://CRAN.R-project.org/package=AMCP>.

</div>

<div id="ref-AMCP">

Maxwell, Scott E, Harold D Delaney, and Ken Kelley. 2017. *Designing Experiments and Analyzing Data: A Model Comparison Perspective*. Routledge.

</div>

<div id="ref-R-jmv">

Selker, Ravi, Jonathon Love, and Damian Dropmann. 2020. *Jmv: The ’Jamovi’ Analyses*. <https://CRAN.R-project.org/package=jmv>.

</div>

<div id="ref-R-tidyverse">

Wickham, Hadley. 2019. *Tidyverse: Easily Install and Load the ’Tidyverse’*. <https://CRAN.R-project.org/package=tidyverse>.

</div>

</div>